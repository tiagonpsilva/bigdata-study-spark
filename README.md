# ğŸ§  Estudo do Apache Spark

Este repositÃ³rio contÃ©m explicaÃ§Ãµes detalhadas e exemplos prÃ¡ticos dos conceitos fundamentais do Apache Spark, com foco em processamento distribuÃ­do de dados em larga escala.

## ğŸ“‹ Ãndice de Conceitos

1. **ğŸ”¥ [Conceitos BÃ¡sicos](./01-conceitos-basicos/README.md)** - Fundamentos, arquitetura, RDDs e contextos do Spark
2. **ğŸ“Š [Spark SQL](./02-spark-sql/README.md)** - Processamento estruturado de dados com DataFrames e SQL
3. **ğŸŒŠ [Spark Streaming](./03-spark-streaming/README.md)** - Processamento de dados em tempo real e integraÃ§Ã£o com Kafka
4. **ğŸ¤– [MLlib](./04-mllib/README.md)** - Machine Learning distribuÃ­do com algoritmos e pipelines
5. **ğŸ•¸ï¸ [GraphX](./05-graphx/README.md)** - Processamento e anÃ¡lise de grafos em larga escala
6. **âš¡ [OtimizaÃ§Ã£o](./06-otimizacao/README.md)** - Tunning, particionamento e monitoramento
7. **ğŸ’¡ [Exemplos](./07-exemplos/README.md)** - Cases prÃ¡ticos e integraÃ§Ãµes

## ğŸŒŸ Objetivo

Este repositÃ³rio tem como objetivo proporcionar um entendimento prÃ¡tico do Apache Spark, com explicaÃ§Ãµes claras e exemplos de casos de uso reais. Cada conceito Ã© explorado em detalhes, com cÃ³digo funcional e boas prÃ¡ticas.

## âš™ï¸ PrÃ©-requisitos

- Java 8 ou superior
- Python 3.7+
- Docker e Docker Compose
- Conhecimento bÃ¡sico de SQL
- Familiaridade com processamento distribuÃ­do

## ğŸš€ Como Usar

1. Clone o repositÃ³rio
```bash
git clone https://github.com/tiagonpsilva/bigdata-study-spark.git
```

2. Navegue atÃ© o diretÃ³rio de exemplos
```bash
cd bigdata-study-spark/exemplos
```

3. Execute o ambiente de laboratÃ³rio
```bash
docker-compose up -d
```

4. Acesse:
   - Spark UI: http://localhost:8080
   - Jupyter: http://localhost:8888
   - History Server: http://localhost:18080

## ğŸ³ Ambiente de Desenvolvimento

### Docker Compose

```yaml
version: '3.8'

services:
  spark-master:
    image: bitnami/spark:3.4
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
    
  spark-worker:
    image: bitnami/spark:3.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  jupyter:
    image: jupyter/pyspark-notebook:latest
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
    environment:
      - SPARK_OPTS="--master=spark://spark-master:7077"
    depends_on:
      - spark-master

  history-server:
    image: bitnami/spark:3.4
    environment:
      - SPARK_MODE=master
    ports:
      - "18080:18080"
    command: /opt/bitnami/spark/sbin/start-history-server.sh
    volumes:
      - spark-logs:/opt/bitnami/spark/logs

volumes:
  spark-logs:
```